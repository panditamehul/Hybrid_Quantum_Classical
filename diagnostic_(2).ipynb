{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gvaahRRKjiX",
        "outputId": "3fe0c50d-4fde-4e4d-b0cb-db5977d86878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Quantum MRI Reconstruction - Diagnostic Pipeline\n",
        "# This is a standalone script for testing the quantum MRI reconstruction pipeline\n",
        "\n",
        "# Install required packages\n",
        "!pip install pennylane torch nibabel matplotlib scikit-image tqdm torchvision -q\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr\n",
        "import pennylane as qml\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from pathlib import Path\n",
        "from torchvision.transforms import functional as TF\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "#To capture time\n",
        "def timing_decorator(func):\n",
        "    \"\"\"Decorator to measure function execution time.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        execution_time = end_time - start_time\n",
        "        print(f\"{func.__name__} executed in {execution_time:.2f} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "# Add this helper function at the top of your script (after the imports)\n",
        "def convert_to_json_serializable(obj):\n",
        "    \"\"\"Convert NumPy types to Python native types for JSON serialization.\"\"\"\n",
        "    if isinstance(obj, (np.integer, np.int32, np.int64)):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, (np.floating, np.float32, np.float64)):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif isinstance(obj, dict):\n",
        "        return {k: convert_to_json_serializable(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, list):\n",
        "        return [convert_to_json_serializable(i) for i in obj]\n",
        "    return obj\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "#=================================================================\n",
        "# IMPROVED K-SPACE UNDERSAMPLING\n",
        "#=================================================================\n",
        "\n",
        "def get_sampling_prob(ny, mode='gaussian', scale=None):\n",
        "    \"\"\"\n",
        "    Get sampling probability distribution along phase-encode dimension.\n",
        "    \"\"\"\n",
        "    y_coords = np.arange(ny)\n",
        "    center = ny / 2\n",
        "    if mode == 'gaussian':\n",
        "        std = ny / 6 if scale is None else ny / scale\n",
        "        prob = np.exp(-((y_coords - center) ** 2) / (2 * std ** 2))\n",
        "    elif mode == 'linear':\n",
        "        prob = 1 - np.abs(y_coords - center) / center\n",
        "    elif mode == 'uniform':\n",
        "        prob = np.ones(ny)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown mode: {mode}\")\n",
        "    prob /= prob.sum()\n",
        "    return prob\n",
        "\n",
        "def generate_variable_density_mask(ny, acceleration, center_fraction=0.08, mode='gaussian', scale=None, seed=None, visualize=False):\n",
        "    \"\"\"\n",
        "    Generate a variable-density undersampling mask for k-space.\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    mask = np.zeros(ny, dtype=bool)\n",
        "\n",
        "    # Always sample center of k-space\n",
        "    center_lines = int(ny * center_fraction)\n",
        "    total_lines = ny // acceleration\n",
        "\n",
        "    if total_lines <= center_lines:\n",
        "        total_lines = center_lines\n",
        "\n",
        "    center_start = (ny - center_lines) // 2\n",
        "    mask[center_start:center_start + center_lines] = True\n",
        "\n",
        "    # Sample remaining lines based on probability distribution\n",
        "    remaining = total_lines - center_lines\n",
        "    prob = get_sampling_prob(ny, mode=mode, scale=scale)\n",
        "\n",
        "    if remaining > 0:\n",
        "        y_coords = np.arange(ny)\n",
        "        outside_center = np.setdiff1d(y_coords, np.arange(center_start, center_start + center_lines))\n",
        "        prob_outside = prob[outside_center]\n",
        "        prob_outside /= prob_outside.sum()\n",
        "        chosen = np.random.choice(outside_center, size=remaining, replace=False, p=prob_outside)\n",
        "        mask[chosen] = True\n",
        "\n",
        "    final_sampled = np.sum(mask)\n",
        "    if visualize:\n",
        "        print(f\"[INFO] Accel={acceleration} | Center={center_lines} | Random={remaining} | Total={final_sampled} / {ny}\")\n",
        "        plt.figure(figsize=(12, 3))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(prob)\n",
        "        plt.title(f\"Sampling Probability ({mode})\")\n",
        "        plt.xlabel(\"Phase-Encode Line\")\n",
        "        plt.ylabel(\"Probability\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(mask.reshape(ny, 1).T, cmap='gray', aspect='auto')\n",
        "        plt.title(\"Mask (1D)\")\n",
        "        plt.yticks([])\n",
        "        plt.xlabel(\"Phase-Encode Line\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return mask.reshape(ny, 1)\n",
        "\n",
        "#=================================================================\n",
        "# DATASET CLASS\n",
        "#=================================================================\n",
        "\n",
        "class DiagnosticNiftiDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A dataset class for NIfTI files with downsampling for faster processing.\n",
        "    \"\"\"\n",
        "    def __init__(self, nifti_files, slice_range=None, acceleration_factor=4,\n",
        "                center_fraction=0.08, mask_mode='gaussian', scale=8.5,\n",
        "                target_size=(64, 64)):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            nifti_files: List of paths to NIfTI files\n",
        "            slice_range: Tuple (min_slice, max_slice) or None to use all slices\n",
        "            acceleration_factor: Undersampling factor (2x or 4x)\n",
        "            center_fraction: Fraction of center k-space to fully sample\n",
        "            mask_mode: Type of sampling pattern ('gaussian', 'linear', 'uniform')\n",
        "            scale: Scale parameter for variable density sampling\n",
        "            target_size: Target size to resize images to (e.g., (64, 64))\n",
        "        \"\"\"\n",
        "        self.nifti_files = nifti_files\n",
        "        self.slice_range = slice_range\n",
        "        self.acceleration_factor = acceleration_factor\n",
        "        self.center_fraction = center_fraction\n",
        "        self.mask_mode = mask_mode\n",
        "        self.scale = scale\n",
        "        self.target_size = target_size\n",
        "\n",
        "        # Create a list of (file_idx, slice_idx) tuples for all slices\n",
        "        self.slices = []\n",
        "\n",
        "        print(f\"Loading {len(nifti_files)} NIfTI files...\")\n",
        "        for file_idx, file_path in enumerate(nifti_files):\n",
        "            try:\n",
        "                # Load NIfTI file\n",
        "                img = nib.load(file_path)\n",
        "                data = img.get_fdata()\n",
        "\n",
        "                # Get number of slices (assuming last dimension is slices)\n",
        "                n_slices = data.shape[-1]\n",
        "\n",
        "                # Determine slice range\n",
        "                min_slice = 0 if slice_range is None else max(0, slice_range[0])\n",
        "                max_slice = n_slices if slice_range is None else min(n_slices, slice_range[1])\n",
        "\n",
        "                # Add all slices to our list\n",
        "                for slice_idx in range(min_slice, max_slice):\n",
        "                    self.slices.append((file_idx, slice_idx))\n",
        "\n",
        "                print(f\"  File {file_path}: {max_slice - min_slice} slices\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {file_path}: {e}\")\n",
        "\n",
        "        print(f\"Total slices: {len(self.slices)}\")\n",
        "\n",
        "    def _undersample_kspace(self, image):\n",
        "        \"\"\"\n",
        "        Create an undersampled version of the image by applying\n",
        "        a variable density mask in k-space.\n",
        "        \"\"\"\n",
        "        ny, nx = image.shape\n",
        "\n",
        "        # Generate the mask using the improved method\n",
        "        mask_1d = generate_variable_density_mask(\n",
        "            ny,\n",
        "            self.acceleration_factor,\n",
        "            center_fraction=self.center_fraction,\n",
        "            mode=self.mask_mode,\n",
        "            scale=self.scale,\n",
        "            seed=None  # Different mask per slice for diversity\n",
        "        )\n",
        "\n",
        "        # Expand to 2D\n",
        "        mask_2d = np.repeat(mask_1d, nx, axis=1)\n",
        "\n",
        "        # Convert to k-space using FFT\n",
        "        kspace = np.fft.fftshift(np.fft.fft2(image))\n",
        "\n",
        "        # Apply mask\n",
        "        masked_kspace = kspace * mask_2d\n",
        "\n",
        "        # Convert back to image domain using inverse FFT\n",
        "        zero_filled = np.abs(np.fft.ifft2(np.fft.ifftshift(masked_kspace)))\n",
        "\n",
        "        return zero_filled, mask_2d\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.slices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Get a sample from the dataset with resizing.\n",
        "        \"\"\"\n",
        "        file_idx, slice_idx = self.slices[idx]\n",
        "        file_path = self.nifti_files[file_idx]\n",
        "\n",
        "        # Load the NIfTI file\n",
        "        img = nib.load(file_path)\n",
        "        data = img.get_fdata()\n",
        "\n",
        "        # Extract the slice\n",
        "        slice_data = data[:, :, slice_idx]\n",
        "\n",
        "        # Normalize intensity to [0, 1]\n",
        "        slice_min = slice_data.min()\n",
        "        slice_max = slice_data.max()\n",
        "        if slice_max > slice_min:  # Avoid division by zero\n",
        "            slice_data = (slice_data - slice_min) / (slice_max - slice_min)\n",
        "\n",
        "        # Create undersampled version before resizing\n",
        "        zero_filled, mask = self._undersample_kspace(slice_data)\n",
        "\n",
        "        # Resize if target_size is specified\n",
        "        if self.target_size is not None:\n",
        "            # Convert to tensors for resizing\n",
        "            slice_tensor = torch.from_numpy(slice_data).float().unsqueeze(0)\n",
        "            zero_filled_tensor = torch.from_numpy(zero_filled).float().unsqueeze(0)\n",
        "            mask_tensor = torch.from_numpy(mask.astype(np.float32)).unsqueeze(0)\n",
        "\n",
        "            # Resize all tensors\n",
        "            slice_tensor = TF.resize(slice_tensor, self.target_size,\n",
        "                                   interpolation=TF.InterpolationMode.BILINEAR)\n",
        "            zero_filled_tensor = TF.resize(zero_filled_tensor, self.target_size,\n",
        "                                         interpolation=TF.InterpolationMode.BILINEAR)\n",
        "            mask_tensor = TF.resize(mask_tensor, self.target_size,\n",
        "                                  interpolation=TF.InterpolationMode.NEAREST)\n",
        "\n",
        "            # Convert back to numpy arrays\n",
        "            slice_data = slice_tensor.squeeze(0).numpy()\n",
        "            zero_filled = zero_filled_tensor.squeeze(0).numpy()\n",
        "            mask = mask_tensor.squeeze(0).numpy()\n",
        "\n",
        "        # Convert to tensors\n",
        "        fully_sampled = torch.from_numpy(slice_data).float().unsqueeze(0)\n",
        "        zero_filled = torch.from_numpy(zero_filled).float().unsqueeze(0)\n",
        "        mask = torch.from_numpy(mask.astype(np.float32)).unsqueeze(0)\n",
        "\n",
        "        return zero_filled, fully_sampled, mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hODgfK0460jM"
      },
      "outputs": [],
      "source": [
        "\n",
        "#=================================================================\n",
        "# QUANTUM CIRCUIT\n",
        "#=================================================================\n",
        "class FourQubitQuantumCircuit:\n",
        "    def __init__(self):\n",
        "        self.dev = qml.device(\"default.qubit\", wires=4)\n",
        "\n",
        "        @qml.qnode(self.dev, interface=\"auto\")  # use 'auto' to support NumPy or torch\n",
        "        def circuit(x0, x1, x2, x3):\n",
        "            qml.RY(x0, wires=0)\n",
        "            qml.RZ(x0**2, wires=0)\n",
        "\n",
        "            qml.RY(x1, wires=1)\n",
        "            qml.RZ(x1**2, wires=1)\n",
        "\n",
        "            qml.RY(x2, wires=2)\n",
        "            qml.RZ(x2**2, wires=2)\n",
        "\n",
        "            qml.RY(x3, wires=3)\n",
        "            qml.RZ(x3**2, wires=3)\n",
        "\n",
        "            qml.CNOT(wires=[0, 1])\n",
        "            qml.CNOT(wires=[1, 2])\n",
        "            qml.CNOT(wires=[2, 3])\n",
        "            qml.CNOT(wires=[3, 0])  # full ring entanglement\n",
        "\n",
        "            return [qml.expval(qml.PauliZ(i)) for i in range(4)]\n",
        "\n",
        "        self.circuit = circuit\n",
        "\n",
        "    def __call__(self, pixels_batch):\n",
        "        pixels_batch = np.atleast_2d(pixels_batch)\n",
        "        assert pixels_batch.shape[1] == 4, f\"Each input patch must have 4 pixels (got shape {pixels_batch.shape})\"\n",
        "\n",
        "        outputs = []\n",
        "        for pix in pixels_batch:\n",
        "            x0, x1, x2, x3 = pix.tolist()\n",
        "            out = self.circuit(x0, x1, x2, x3)\n",
        "            outputs.append(out)\n",
        "        return np.stack(outputs)\n",
        "\n",
        "#=================================================================\n",
        "# MODEL DEFINITIONS\n",
        "#=================================================================\n",
        "\n",
        "class FourQubitQuantumConv(torch.nn.Module):\n",
        "    def __init__(self, stride=2):\n",
        "        super().__init__()\n",
        "        self.stride = stride\n",
        "        self.circuit = FourQubitQuantumCircuit()\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, height, width = x.shape\n",
        "        out_h = (height - 1) // self.stride + 1\n",
        "        out_w = (width - 1) // self.stride + 1\n",
        "        out = torch.zeros((batch_size, 4, out_h, out_w), device=x.device)\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            patches = []\n",
        "            for i in range(0, height - 1, self.stride):\n",
        "                for j in range(0, width - 1, self.stride):\n",
        "                    patch = x[b, 0, i:i+2, j:j+2].reshape(-1)\n",
        "                    if patch.shape[0] == 4:\n",
        "                        patches.append(patch.detach().cpu().numpy())\n",
        "\n",
        "            # Apply circuit in batch\n",
        "            outputs = self.circuit(patches)\n",
        "            outputs = torch.tensor(outputs, device=x.device)\n",
        "\n",
        "            # Reshape into output image\n",
        "            idx = 0\n",
        "            for i in range(out_h):\n",
        "                for j in range(out_w):\n",
        "                    if idx < len(outputs):\n",
        "                        out[b, :, i, j] = outputs[idx]\n",
        "                        idx += 1\n",
        "\n",
        "        return out\n",
        "\n",
        "## MORE COMPLEX WITH ADDITIONAL CLASSICAL COMPLEXITY (QUANTUM KEPT SAME)\n",
        "class DiagnosticQuantumUNet(torch.nn.Module):\n",
        "    def __init__(self, stride=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # Quantum convolution layer (still outputs 2 channels)\n",
        "        self.quantum_conv = FourQubitQuantumConv(stride=stride)\n",
        "\n",
        "        # Encoder path (expanded)\n",
        "        self.enc1 = self.conv_block(4, 64)  # ✅ now expects 4-channel quantum output\n",
        "        self.pool1 = torch.nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc2 = self.conv_block(64, 128)\n",
        "        self.pool2 = torch.nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc3 = self.conv_block(128, 256)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = self.conv_block(256, 512)\n",
        "\n",
        "        # Decoder path (mirroring encoder)\n",
        "        self.up1 = torch.nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec1 = self.conv_block(512, 256)  # 256 + 256\n",
        "\n",
        "        self.up2 = torch.nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec2 = self.conv_block(256, 128)  # 128 + 128\n",
        "\n",
        "        self.up3 = torch.nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec3 = self.conv_block(128, 64)   # 64 + 64\n",
        "\n",
        "        # Final 1×1 conv + upsampling\n",
        "        self.final = torch.nn.Conv2d(64, 1, kernel_size=1)\n",
        "        self.final_up = torch.nn.ConvTranspose2d(1, 1, kernel_size=stride, stride=stride)\n",
        "\n",
        "    def conv_block(self, in_ch, out_ch):\n",
        "        return torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "            torch.nn.BatchNorm2d(out_ch),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "            torch.nn.BatchNorm2d(out_ch),\n",
        "            torch.nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quantum_conv(x)\n",
        "\n",
        "        # Encoder\n",
        "        enc1 = self.enc1(x)\n",
        "        x = self.pool1(enc1)\n",
        "\n",
        "        enc2 = self.enc2(x)\n",
        "        x = self.pool2(enc2)\n",
        "\n",
        "        enc3 = self.enc3(x)\n",
        "        x = self.bottleneck(enc3)\n",
        "\n",
        "        # Decoder 1\n",
        "        x = self.up1(x)\n",
        "        x = self._pad_and_concat(x, enc3)\n",
        "        x = self.dec1(x)\n",
        "\n",
        "        # Decoder 2\n",
        "        x = self.up2(x)\n",
        "        x = self._pad_and_concat(x, enc2)\n",
        "        x = self.dec2(x)\n",
        "\n",
        "        # Decoder 3\n",
        "        x = self.up3(x)\n",
        "        x = self._pad_and_concat(x, enc1)\n",
        "        x = self.dec3(x)\n",
        "\n",
        "        x = self.final(x)\n",
        "        x = self.final_up(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _pad_and_concat(self, upsampled, skip):\n",
        "        diff_y = skip.size()[2] - upsampled.size()[2]\n",
        "        diff_x = skip.size()[3] - upsampled.size()[3]\n",
        "        upsampled = F.pad(upsampled, [diff_x // 2, diff_x - diff_x // 2,\n",
        "                                      diff_y // 2, diff_y - diff_y // 2])\n",
        "        return torch.cat([upsampled, skip], dim=1)\n",
        "\n",
        "class DiagnosticClassicalUNet(torch.nn.Module):\n",
        "    def __init__(self, stride=4):\n",
        "        super().__init__()\n",
        "\n",
        "        # Simulates quantum downsampling with classical 1x2 conv\n",
        "        self.conv0 = torch.nn.Conv2d(1, 4, kernel_size=(2, 2), stride=stride)  # mimic 2×2 patch behavior\n",
        "        self.relu0 = torch.nn.ReLU(inplace=True)\n",
        "\n",
        "        # Encoder path (expanded)\n",
        "        self.enc1 = self.conv_block(4, 64)\n",
        "        self.pool1 = torch.nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc2 = self.conv_block(64, 128)\n",
        "        self.pool2 = torch.nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc3 = self.conv_block(128, 256)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = self.conv_block(256, 512)\n",
        "\n",
        "        # Decoder path\n",
        "        self.up1 = torch.nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec1 = self.conv_block(512, 256)\n",
        "\n",
        "        self.up2 = torch.nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec2 = self.conv_block(256, 128)\n",
        "\n",
        "        self.up3 = torch.nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec3 = self.conv_block(128, 64)\n",
        "\n",
        "        # Final layer + resolution restore\n",
        "        self.final = torch.nn.Conv2d(64, 1, kernel_size=1)\n",
        "        self.final_up = torch.nn.ConvTranspose2d(1, 1, kernel_size=stride, stride=stride)\n",
        "\n",
        "    def conv_block(self, in_ch, out_ch):\n",
        "        return torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "            torch.nn.BatchNorm2d(out_ch),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "            torch.nn.BatchNorm2d(out_ch),\n",
        "            torch.nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu0(self.conv0(x))\n",
        "\n",
        "        enc1 = self.enc1(x)\n",
        "        x = self.pool1(enc1)\n",
        "\n",
        "        enc2 = self.enc2(x)\n",
        "        x = self.pool2(enc2)\n",
        "\n",
        "        enc3 = self.enc3(x)\n",
        "        x = self.bottleneck(enc3)\n",
        "\n",
        "        # Decoder\n",
        "        x = self.up1(x)\n",
        "        x = self._pad_and_concat(x, enc3)\n",
        "        x = self.dec1(x)\n",
        "\n",
        "        x = self.up2(x)\n",
        "        x = self._pad_and_concat(x, enc2)\n",
        "        x = self.dec2(x)\n",
        "\n",
        "        x = self.up3(x)\n",
        "        x = self._pad_and_concat(x, enc1)\n",
        "        x = self.dec3(x)\n",
        "\n",
        "        x = self.final(x)\n",
        "        x = self.final_up(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _pad_and_concat(self, upsampled, skip):\n",
        "        diff_y = skip.size()[2] - upsampled.size()[2]\n",
        "        diff_x = skip.size()[3] - upsampled.size()[3]\n",
        "        upsampled = F.pad(upsampled, [diff_x // 2, diff_x - diff_x // 2,\n",
        "                                      diff_y // 2, diff_y - diff_y // 2])\n",
        "        return torch.cat([upsampled, skip], dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTt0-HhD63uR"
      },
      "outputs": [],
      "source": [
        "\n",
        "#=================================================================\n",
        "# TRAINING FUNCTION\n",
        "#=================================================================\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=2, lr=0.001, device='cpu',\n",
        "               save_path=None, model_name=\"quantum_mri\"):\n",
        "    \"\"\"\n",
        "    Train the model for a specified number of epochs.\n",
        "\n",
        "    Args:\n",
        "        model: The model to train\n",
        "        train_loader: DataLoader for training\n",
        "        val_loader: DataLoader for validation\n",
        "        num_epochs: Number of epochs to train for\n",
        "        lr: Learning rate\n",
        "        device: Device to train on ('cpu' or 'cuda')\n",
        "        save_path: Directory to save model checkpoints\n",
        "        model_name: Name for saved model files\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of training history\n",
        "    \"\"\"\n",
        "    # Create save directory if needed\n",
        "    if save_path is not None:\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    # Move model to device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Prepare for training\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'val_metrics': []\n",
        "    }\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        with tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}') as pbar:\n",
        "            for batch_idx, (zero_filled, fully_sampled, _) in enumerate(train_loader):\n",
        "                # Move data to device\n",
        "                zero_filled = zero_filled.to(device)\n",
        "                fully_sampled = fully_sampled.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(zero_filled)\n",
        "\n",
        "                # Resize target to match output size if needed\n",
        "                if outputs.shape != fully_sampled.shape:\n",
        "                    fully_sampled = TF.resize(fully_sampled, outputs.shape[2:],\n",
        "                                           interpolation=TF.InterpolationMode.BILINEAR)\n",
        "\n",
        "                # Calculate loss\n",
        "                loss = criterion(outputs, fully_sampled)\n",
        "\n",
        "                # Backward pass and optimize\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Update statistics\n",
        "                train_loss += loss.item()\n",
        "                pbar.update(1)\n",
        "                pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        # Calculate average training loss\n",
        "        train_loss /= len(train_loader)\n",
        "        history['train_loss'].append(train_loss)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_metrics = {'mse': [], 'psnr': [], 'ssim': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for zero_filled, fully_sampled, _ in val_loader:\n",
        "                zero_filled = zero_filled.to(device)\n",
        "                fully_sampled = fully_sampled.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(zero_filled)\n",
        "\n",
        "                # Resize target to match output size if needed\n",
        "                if outputs.shape != fully_sampled.shape:\n",
        "                    fully_sampled = TF.resize(fully_sampled, outputs.shape[2:],\n",
        "                                           interpolation=TF.InterpolationMode.BILINEAR)\n",
        "\n",
        "                loss = criterion(outputs, fully_sampled)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                # Calculate metrics for each sample\n",
        "                for i in range(outputs.size(0)):\n",
        "                    output_np = outputs[i, 0].cpu().numpy()\n",
        "                    target_np = fully_sampled[i, 0].cpu().numpy()\n",
        "\n",
        "                    # Calculate metrics\n",
        "                    mse = np.mean((output_np - target_np) ** 2)\n",
        "                    val_metrics['mse'].append(mse)\n",
        "\n",
        "                    max_val = 1.0\n",
        "                    val_metrics['psnr'].append(\n",
        "                        psnr(target_np, output_np, data_range=max_val)\n",
        "                    )\n",
        "                    val_metrics['ssim'].append(\n",
        "                        ssim(target_np, output_np, data_range=max_val)\n",
        "                    )\n",
        "\n",
        "        # Calculate average validation loss and metrics\n",
        "        val_loss /= len(val_loader)\n",
        "        history['val_loss'].append(val_loss)\n",
        "\n",
        "        avg_metrics = {\n",
        "            'mse': np.mean(val_metrics['mse']),\n",
        "            'psnr': np.mean(val_metrics['psnr']),\n",
        "            'ssim': np.mean(val_metrics['ssim'])\n",
        "        }\n",
        "        history['val_metrics'].append(avg_metrics)\n",
        "\n",
        "        # Print epoch statistics\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
        "        print(f\"  Train Loss: {train_loss:.6f}\")\n",
        "        print(f\"  Val Loss: {val_loss:.6f}\")\n",
        "        print(f\"  MSE: {avg_metrics['mse']:.6f}\")\n",
        "        print(f\"  PSNR: {avg_metrics['psnr']:.2f} dB\")\n",
        "        print(f\"  SSIM: {avg_metrics['ssim']:.4f}\")\n",
        "\n",
        "        # Save model if it's the best so far\n",
        "        if val_loss < best_val_loss and save_path is not None:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': val_loss,\n",
        "                'metrics': avg_metrics\n",
        "            }, os.path.join(save_path, f\"{model_name}_best.pth\"))\n",
        "            print(f\"  Saved best model (val_loss: {val_loss:.6f})\")\n",
        "\n",
        "        # Save checkpoint every epoch\n",
        "        if save_path is not None:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': val_loss,\n",
        "                'metrics': avg_metrics\n",
        "            }, os.path.join(save_path, f\"{model_name}_epoch{epoch+1}.pth\"))\n",
        "\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rxvz8FwCVfv"
      },
      "outputs": [],
      "source": [
        "!pip install torchsummary -q\n",
        "\n",
        "\n",
        "#=================================================================\n",
        "# VISUALIZATION AND EVALUATION FUNCTIONS\n",
        "#=================================================================\n",
        "\n",
        "def visualize_dataset_samples(dataset, num_samples=3):\n",
        "    \"\"\"\n",
        "    Display some samples from the dataset to verify preprocessing.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 5*num_samples))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        try:\n",
        "            zero_filled, fully_sampled, mask = dataset[i]\n",
        "\n",
        "            # Convert tensors to numpy arrays for visualization\n",
        "            zero_filled = zero_filled.squeeze().numpy()\n",
        "            fully_sampled = fully_sampled.squeeze().numpy()\n",
        "            mask = mask.squeeze().numpy()\n",
        "\n",
        "            # Calculate error map\n",
        "            error = np.abs(fully_sampled - zero_filled)\n",
        "\n",
        "            # Calculate metrics\n",
        "            ssim_val = ssim(fully_sampled, zero_filled, data_range=1.0)\n",
        "            psnr_val = psnr(fully_sampled, zero_filled, data_range=1.0)\n",
        "\n",
        "            # Display\n",
        "            plt.subplot(num_samples, 4, i*4 + 1)\n",
        "            plt.imshow(fully_sampled, cmap='gray')\n",
        "            plt.title('Fully Sampled')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(num_samples, 4, i*4 + 2)\n",
        "            plt.imshow(zero_filled, cmap='gray')\n",
        "            plt.title(f'Zero-Filled (PSNR: {psnr_val:.2f})')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(num_samples, 4, i*4 + 3)\n",
        "            plt.imshow(error, cmap='hot')\n",
        "            plt.title(f'Error (SSIM: {ssim_val:.4f})')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(num_samples, 4, i*4 + 4)\n",
        "            plt.imshow(mask, cmap='gray')\n",
        "            plt.title('k-space Mask')\n",
        "            plt.axis('off')\n",
        "\n",
        "        except IndexError:\n",
        "            break\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def compare_models(quantum_model, classical_model, test_loader, device='cpu'):\n",
        "    \"\"\"\n",
        "    Compare the quantum and classical models on the same test data.\n",
        "    \"\"\"\n",
        "    quantum_model.eval()\n",
        "    classical_model.eval()\n",
        "\n",
        "    # Metrics\n",
        "    q_metrics = {\n",
        "        'mse': [],\n",
        "        'psnr': [],\n",
        "        'ssim': []\n",
        "    }\n",
        "\n",
        "    c_metrics = {\n",
        "        'mse': [],\n",
        "        'psnr': [],\n",
        "        'ssim': []\n",
        "    }\n",
        "\n",
        "    # Get some samples for visualization\n",
        "    vis_samples = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (zero_filled, fully_sampled, mask) in enumerate(test_loader):\n",
        "            zero_filled = zero_filled.to(device)\n",
        "            fully_sampled = fully_sampled.to(device)\n",
        "\n",
        "            # Forward pass for both models\n",
        "            q_outputs = quantum_model(zero_filled)\n",
        "            c_outputs = classical_model(zero_filled)\n",
        "\n",
        "            # Resize target to match output sizes if needed\n",
        "            if q_outputs.shape != fully_sampled.shape:\n",
        "                q_target = TF.resize(fully_sampled, q_outputs.shape[2:],\n",
        "                                   interpolation=TF.InterpolationMode.BILINEAR)\n",
        "            else:\n",
        "                q_target = fully_sampled\n",
        "\n",
        "            if c_outputs.shape != fully_sampled.shape:\n",
        "                c_target = TF.resize(fully_sampled, c_outputs.shape[2:],\n",
        "                                   interpolation=TF.InterpolationMode.BILINEAR)\n",
        "            else:\n",
        "                c_target = fully_sampled\n",
        "\n",
        "            # Calculate metrics for each sample\n",
        "            for i in range(zero_filled.size(0)):\n",
        "                q_output_np = q_outputs[i, 0].cpu().numpy()\n",
        "                c_output_np = c_outputs[i, 0].cpu().numpy()\n",
        "                q_target_np = q_target[i, 0].cpu().numpy()\n",
        "                c_target_np = c_target[i, 0].cpu().numpy()\n",
        "                input_np = zero_filled[i, 0].cpu().numpy()\n",
        "\n",
        "                # Calculate metrics for quantum model\n",
        "                q_mse = np.mean((q_output_np - q_target_np) ** 2)\n",
        "                q_metrics['mse'].append(q_mse)\n",
        "\n",
        "                max_val = 1.0\n",
        "                q_metrics['psnr'].append(\n",
        "                    psnr(q_target_np, q_output_np, data_range=max_val)\n",
        "                )\n",
        "                q_metrics['ssim'].append(\n",
        "                    ssim(q_target_np, q_output_np, data_range=max_val)\n",
        "                )\n",
        "\n",
        "                # Calculate metrics for classical model\n",
        "                c_mse = np.mean((c_output_np - c_target_np) ** 2)\n",
        "                c_metrics['mse'].append(c_mse)\n",
        "\n",
        "                c_metrics['psnr'].append(\n",
        "                    psnr(c_target_np, c_output_np, data_range=max_val)\n",
        "                )\n",
        "                c_metrics['ssim'].append(\n",
        "                    ssim(c_target_np, c_output_np, data_range=max_val)\n",
        "                )\n",
        "\n",
        "                # Store some samples for visualization\n",
        "                if len(vis_samples) < 3 and batch_idx % 2 == 0:\n",
        "                    # Make sure all samples are the same size for visualization\n",
        "                    min_h = min(q_output_np.shape[0], c_output_np.shape[0], input_np.shape[0])\n",
        "                    min_w = min(q_output_np.shape[1], c_output_np.shape[1], input_np.shape[1])\n",
        "\n",
        "                    # Resize for visualization if needed\n",
        "                    if input_np.shape != (min_h, min_w):\n",
        "                        input_np_tensor = torch.from_numpy(input_np).unsqueeze(0)\n",
        "                        input_np = TF.resize(input_np_tensor, (min_h, min_w)).squeeze(0).numpy()\n",
        "\n",
        "                    if q_output_np.shape != (min_h, min_w):\n",
        "                        q_output_np_tensor = torch.from_numpy(q_output_np).unsqueeze(0)\n",
        "                        q_output_np = TF.resize(q_output_np_tensor, (min_h, min_w)).squeeze(0).numpy()\n",
        "\n",
        "                    if c_output_np.shape != (min_h, min_w):\n",
        "                        c_output_np_tensor = torch.from_numpy(c_output_np).unsqueeze(0)\n",
        "                        c_output_np = TF.resize(c_output_np_tensor, (min_h, min_w)).squeeze(0).numpy()\n",
        "\n",
        "                    # Store sample\n",
        "                    vis_samples.append({\n",
        "                        'input': input_np,\n",
        "                        'q_output': q_output_np,\n",
        "                        'c_output': c_output_np,\n",
        "                        'target': q_target_np if q_target_np.shape == (min_h, min_w) else\n",
        "                                TF.resize(torch.from_numpy(q_target_np).unsqueeze(0),\n",
        "                                        (min_h, min_w)).squeeze(0).numpy(),\n",
        "                        'q_metrics': {\n",
        "                            'mse': q_mse,\n",
        "                            'psnr': q_metrics['psnr'][-1],\n",
        "                            'ssim': q_metrics['ssim'][-1]\n",
        "                        },\n",
        "                        'c_metrics': {\n",
        "                            'mse': c_mse,\n",
        "                            'psnr': c_metrics['psnr'][-1],\n",
        "                            'ssim': c_metrics['ssim'][-1]\n",
        "                        }\n",
        "                    })\n",
        "\n",
        "    # Calculate average metrics\n",
        "    avg_q_mse = np.mean(q_metrics['mse'])\n",
        "    avg_q_psnr = np.mean(q_metrics['psnr'])\n",
        "    avg_q_ssim = np.mean(q_metrics['ssim'])\n",
        "\n",
        "    avg_c_mse = np.mean(c_metrics['mse'])\n",
        "    avg_c_psnr = np.mean(c_metrics['psnr'])\n",
        "    avg_c_ssim = np.mean(c_metrics['ssim'])\n",
        "\n",
        "    # Improvement percentages\n",
        "    mse_improvement = (avg_c_mse - avg_q_mse) / avg_c_mse * 100\n",
        "    psnr_improvement = (avg_q_psnr - avg_c_psnr) / avg_c_psnr * 100\n",
        "    ssim_improvement = (avg_q_ssim - avg_c_ssim) / avg_c_ssim * 100\n",
        "\n",
        "    print(\"\\nModel Comparison:\")\n",
        "    print(f\"  Quantum MSE: {avg_q_mse:.6f}, Classical MSE: {avg_c_mse:.6f} ({mse_improvement:.2f}% improvement)\")\n",
        "    print(f\"  Quantum PSNR: {avg_q_psnr:.2f} dB, Classical PSNR: {avg_c_psnr:.2f} dB ({psnr_improvement:.2f}% improvement)\")\n",
        "    print(f\"  Quantum SSIM: {avg_q_ssim:.4f}, Classical SSIM: {avg_c_ssim:.4f} ({ssim_improvement:.2f}% improvement)\")\n",
        "\n",
        "    # Visualize comparison\n",
        "    plt.figure(figsize=(15, 5 * len(vis_samples)))\n",
        "\n",
        "    for i, sample in enumerate(vis_samples):\n",
        "        # Display\n",
        "        plt.subplot(len(vis_samples), 4, i*4 + 1)\n",
        "        plt.imshow(sample['target'], cmap='gray')\n",
        "        plt.title('Ground Truth')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(len(vis_samples), 4, i*4 + 2)\n",
        "        plt.imshow(sample['input'], cmap='gray')\n",
        "        plt.title('Zero-Filled Input')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(len(vis_samples), 4, i*4 + 3)\n",
        "        plt.imshow(sample['q_output'], cmap='gray')\n",
        "        plt.title(f'Quantum Output\\nPSNR: {sample[\"q_metrics\"][\"psnr\"]:.2f}, SSIM: {sample[\"q_metrics\"][\"ssim\"]:.4f}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(len(vis_samples), 4, i*4 + 4)\n",
        "        plt.imshow(sample['c_output'], cmap='gray')\n",
        "        plt.title(f'Classical Output\\nPSNR: {sample[\"c_metrics\"][\"psnr\"]:.2f}, SSIM: {sample[\"c_metrics\"][\"ssim\"]:.4f}')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Bar chart comparison\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # MSE (lower is better)\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.bar(['Quantum', 'Classical'], [avg_q_mse, avg_c_mse])\n",
        "    plt.title('MSE (lower is better)')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "\n",
        "    # PSNR (higher is better)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.bar(['Quantum', 'Classical'], [avg_q_psnr, avg_c_psnr])\n",
        "    plt.title('PSNR (higher is better)')\n",
        "    plt.ylabel('Peak Signal-to-Noise Ratio (dB)')\n",
        "\n",
        "    # SSIM (higher is better)\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.bar(['Quantum', 'Classical'], [avg_q_ssim, avg_c_ssim])\n",
        "    plt.title('SSIM (higher is better)')\n",
        "    plt.ylabel('Structural Similarity Index')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'quantum': {\n",
        "            'mse': avg_q_mse,\n",
        "            'psnr': avg_q_psnr,\n",
        "            'ssim': avg_q_ssim\n",
        "        },\n",
        "        'classical': {\n",
        "            'mse': avg_c_mse,\n",
        "            'psnr': avg_c_psnr,\n",
        "            'ssim': avg_c_ssim\n",
        "        },\n",
        "        'improvement': {\n",
        "            'mse': mse_improvement,\n",
        "            'psnr': psnr_improvement,\n",
        "            'ssim': ssim_improvement\n",
        "        }\n",
        "    }\n",
        "\n",
        "def print_model_summary(quantum_model, classical_model):\n",
        "    from torchsummary import summary\n",
        "\n",
        "    print(\"\\n🔍 MODEL ARCHITECTURE SUMMARY\")\n",
        "    print(\"=\"*40)\n",
        "    print(\"\\n📦 Quantum Model Summary:\")\n",
        "    try:\n",
        "        summary(quantum_model, (1, 64, 64))\n",
        "    except:\n",
        "        print(\"  (torchsummary not installed or error in quantum layer — skip)\")\n",
        "\n",
        "    print(\"\\n📦 Classical Model Summary:\")\n",
        "    try:\n",
        "        summary(classical_model, (1, 64, 64))\n",
        "    except:\n",
        "        print(\"  (torchsummary not installed — skip)\")\n",
        "\n",
        "\n",
        "def plot_training_history(history, save_path=None):\n",
        "    \"\"\"\n",
        "    Plot the training history including loss and metrics.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Val Loss')\n",
        "    plt.title('Loss During Training')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot MSE\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot([m['mse'] for m in history['val_metrics']])\n",
        "    plt.title('MSE on Validation Set')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('MSE')\n",
        "\n",
        "    # Plot PSNR\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot([m['psnr'] for m in history['val_metrics']])\n",
        "    plt.title('PSNR on Validation Set')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('PSNR (dB)')\n",
        "\n",
        "    # Plot SSIM\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot([m['ssim'] for m in history['val_metrics']])\n",
        "    plt.title('SSIM on Validation Set')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('SSIM')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo3cAxijK4K8"
      },
      "outputs": [],
      "source": [
        "#=================================================================\n",
        "# MAIN EXECUTION\n",
        "#=================================================================\n",
        "\n",
        "overall_start_time = time.time()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify paths to your NIfTI files\n",
        "    nifti_files = [\n",
        "        \"/content/sub-ADNI011S0003_brain.nii.gz\",\n",
        "        \"/content/sub-ADNI022S0004_brain.nii.gz\",\n",
        "        \"/content/sub-ADNI100S5280_brain.nii.gz\"\n",
        "    ]\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs('output', exist_ok=True)\n",
        "\n",
        "    print(\"\\n=== RUNNING DIAGNOSTIC MODE ===\\n\")\n",
        "\n",
        "    # Use only one file for diagnostic\n",
        "    # diagnostic_files = [nifti_files[0]]\n",
        "\n",
        "    # Create dataset with downsampling\n",
        "    print(\"Creating dataset...\")\n",
        "    dataset = DiagnosticNiftiDataset(\n",
        "        nifti_files=nifti_files[:2],\n",
        "        slice_range=(50, 100),\n",
        "        acceleration_factor= 2,\n",
        "        target_size=(64, 64)\n",
        "    )\n",
        "\n",
        "    dataset_time = time.time()\n",
        "    print(f\"Dataset creation time: {dataset_time - overall_start_time:.2f} seconds\")\n",
        "\n",
        "    # Visualize dataset samples\n",
        "    print(\"\\nVisualizing dataset samples...\")\n",
        "    visualize_dataset_samples(dataset, num_samples=3)\n",
        "\n",
        "    # Test the 2-qubit circuit\n",
        "    print(\"\\nTesting quantum circuit...\")\n",
        "    # circuit = FastQuantumCircuit()\n",
        "    circuit = FourQubitQuantumCircuit()\n",
        "    test_pixels = np.array([0.1, 0.2, 0.3, 0.4])  # 2×2 patch flattened\n",
        "    output = circuit(test_pixels)\n",
        "    print(f\"2-qubit circuit test - Input: {test_pixels}, Output: {output}\")\n",
        "\n",
        "    # Split data\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    print(f\"Training set: {len(train_dataset)} slices\")\n",
        "    print(f\"Validation set: {len(val_dataset)} slices\")\n",
        "\n",
        "    # Create data loaders\n",
        "    batch_size = 2\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Check for GPU availability\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # # Initialize simplified models\n",
        "    # quantum_model = DiagnosticQuantumMRINet(stride=4)\n",
        "    # classical_model = DiagnosticClassicalMRINet(stride=4)\n",
        "\n",
        "    # Simplistic UNet models\n",
        "    quantum_model = DiagnosticQuantumUNet(stride=2)\n",
        "    classical_model = DiagnosticClassicalUNet(stride=2)\n",
        "\n",
        "    # Initialize enhanced U-Net models\n",
        "    # quantum_model = EnhancedDiagnosticQuantumUNet(stride=4)\n",
        "    # classical_model = EnhancedDiagnosticClassicalUNet(stride=4)\n",
        "\n",
        "    q_train_start = time.time()\n",
        "\n",
        "    # Train quantum model\n",
        "    print(\"\\nTraining quantum model...\")\n",
        "    q_history = train_model(\n",
        "        model=quantum_model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        num_epochs = 10,\n",
        "        lr=0.001,\n",
        "        device=device,\n",
        "        save_path='output',\n",
        "        model_name=\"quantum_mri_diagnostic\"\n",
        "    )\n",
        "\n",
        "    q_train_end = time.time()\n",
        "    print(f\"Quantum model training time: {q_train_end - q_train_start:.2f} seconds\")\n",
        "\n",
        "    # Plot training history\n",
        "    print(\"\\nPlotting quantum model training history...\")\n",
        "    plot_training_history(q_history, save_path='output/quantum_training_history.png')\n",
        "\n",
        "    c_train_start = time.time()\n",
        "\n",
        "    # Train classical model\n",
        "    print(\"\\nTraining classical model...\")\n",
        "    c_history = train_model(\n",
        "        model=classical_model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        num_epochs = 10,\n",
        "        lr=0.001,\n",
        "        device=device,\n",
        "        save_path='output',\n",
        "        model_name=\"classical_mri_diagnostic\"\n",
        "    )\n",
        "\n",
        "    c_train_end = time.time()\n",
        "    print(f\"Classical model training time: {c_train_end - c_train_start:.2f} seconds\")\n",
        "\n",
        "    # Compare models\n",
        "    print(\"\\nComparing models...\")\n",
        "    comparison = compare_models(quantum_model, classical_model, val_loader, device)\n",
        "\n",
        "    # Plot classical model training history\n",
        "    print(\"\\nPlotting classical model training history...\")\n",
        "    plot_training_history(c_history, save_path='output/classical_training_history.png')\n",
        "\n",
        "    # Save results\n",
        "    import json\n",
        "    with open('output/diagnostic_results.json', 'w') as f:\n",
        "        serializable_results = convert_to_json_serializable({\n",
        "            'quantum_metrics': comparison['quantum'],\n",
        "            'classical_metrics': comparison['classical'],\n",
        "            'improvement': comparison['improvement']\n",
        "        })\n",
        "        json.dump(serializable_results, f, indent=2)\n",
        "\n",
        "    print(\"\\nDiagnostic run completed! Results saved to 'output/diagnostic_results.json'.\")\n",
        "\n",
        "    overall_end_time = time.time()\n",
        "    total_execution_time = overall_end_time - overall_start_time\n",
        "    print(f\"\\nTotal execution time: {total_execution_time:.2f} seconds ({total_execution_time/60:.2f} minutes)\")\n",
        "\n",
        "    ### MODEL SUMMARY\n",
        "    print_model_summary(quantum_model, classical_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC16wugV1-dw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MIX6a1t0QNC0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}